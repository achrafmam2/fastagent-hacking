{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream\n",
    "\n",
    "> Stream data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import asyncio\n",
    "import functools\n",
    "import abc\n",
    "import enum\n",
    "from typing import AsyncIterable, AsyncIterator, Iterable, TypeVar, Generic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "_T = TypeVar(\"T\")\n",
    "\n",
    "\n",
    "class StreamStatus(enum.Enum):\n",
    "  OK = enum.auto()\n",
    "  SHUTDOWN = enum.auto()\n",
    "\n",
    "\n",
    "class Stream(abc.ABC, AsyncIterator[_T]):\n",
    "\n",
    "  @abc.abstractmethod\n",
    "  async def next(\n",
    "      self,\n",
    "      with_status: bool = False,\n",
    "  ) -> _T | None:\n",
    "    pass\n",
    "\n",
    "  async def __anext__(self) -> _T:\n",
    "    e, status = await self.next(with_status=True)\n",
    "    if status == StreamStatus.SHUTDOWN:\n",
    "      raise StopAsyncIteration\n",
    "    return e\n",
    "\n",
    "  def __aiter__(self) -> AsyncIterator[_T]:\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StreamWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "class StreamWriter(abc.ABC, Generic[_T]):\n",
    "\n",
    "  @abc.abstractmethod\n",
    "  async def put(self, *items: _T):\n",
    "    pass\n",
    "\n",
    "  @abc.abstractmethod\n",
    "  async def shutdown(self):\n",
    "    pass\n",
    "\n",
    "  @abc.abstractmethod\n",
    "  def readonly(self) -> Stream[_T]:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "class InMemStreamWriter(StreamWriter[_T]):\n",
    "\n",
    "  def __init__(self):\n",
    "    self._q = asyncio.Queue()\n",
    "    self._lock = asyncio.Lock()\n",
    "\n",
    "  async def put(self, *items: _T):\n",
    "    async with self._lock:\n",
    "      # Lock to ensure all elements are enqueued without being shutdown.\n",
    "      try:\n",
    "        for item in items:\n",
    "          await self._q.put(item)\n",
    "      except asyncio.QueueShutDown:\n",
    "        pass\n",
    "\n",
    "  async def shutdown(self):\n",
    "    async with self._lock:\n",
    "      self._q.shutdown()\n",
    "\n",
    "  def readonly(self) -> Stream[_T]:\n",
    "\n",
    "    async def _next(w: InMemStreamWriter[_T],\n",
    "                    *,\n",
    "                    with_status: bool = False) -> _T | None:\n",
    "      item, status = None, StreamStatus.OK\n",
    "      try:\n",
    "        item = await w._q.get()\n",
    "        w._q.task_done()\n",
    "      except asyncio.QueueShutDown:\n",
    "        item, status = None, StreamStatus.SHUTDOWN\n",
    "\n",
    "      if with_status:\n",
    "        return item, status\n",
    "      return item\n",
    "\n",
    "    class _S(Stream[_T]):\n",
    "      next = lambda _, *args, **kwargs: _next(self, *args, **kwargs)\n",
    "\n",
    "    return _S()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InMemStreamWriter tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = InMemStreamWriter()\n",
    "sr = sw.readonly()\n",
    "\n",
    "_access_pattern = []  # P: Producer, C: Consumer.\n",
    "\n",
    "\n",
    "async def producer():\n",
    "  for i in range(3):\n",
    "    global _access_pattern\n",
    "    await asyncio.sleep(0.01)\n",
    "    _access_pattern.append((\"P\", i))\n",
    "    await sw.put(i)\n",
    "  await sw.shutdown()\n",
    "\n",
    "\n",
    "async def consumer():\n",
    "  async for e in sr:\n",
    "    _access_pattern.append((\"C\", e))\n",
    "\n",
    "\n",
    "async with asyncio.TaskGroup() as tg:\n",
    "  tg.create_task(consumer())\n",
    "  tg.create_task(producer())\n",
    "\n",
    "test_eq(_access_pattern, [(\"P\", 0), (\"C\", 0), (\"P\", 1), (\"C\", 1), (\"P\", 2), (\"C\", 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = InMemStreamWriter()\n",
    "sr = sw.readonly()\n",
    "\n",
    "await sw.put(\"a\", \"b\")\n",
    "\n",
    "# await sw.shutdown()\n",
    "await sw.shutdown() # No-op.\n",
    "\n",
    "test_eq(await sr.next(), \"a\")\n",
    "test_eq(await sr.next(), \"b\")\n",
    "\n",
    "await sw.put(\"c\") # No-op.\n",
    "test_eq(await sr.next(), None)\n",
    "test_eq(await sr.next(with_status=True), (None, StreamStatus.SHUTDOWN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream Utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tolist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "async def tolist(s: Stream[_T]) -> list[_T]:\n",
    "  xs = []\n",
    "  async for x in s:\n",
    "    xs.append(x)\n",
    "  return xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def of(*args: _T | AsyncIterable[_T] | Iterable[_T]) -> Stream[_T]:\n",
    "  \"\"\"Returns a Stream from the given source(s).\"\"\"\n",
    "\n",
    "  class _FromIterableStream(Stream[_T]):\n",
    "\n",
    "    def __init__(self, source: AsyncIterable[_T] | Iterable[_T]):\n",
    "      if isinstance(source, AsyncIterable):\n",
    "        self._iter = source.__aiter__()\n",
    "      else:\n",
    "        self._iter = self._to_aiter(source)\n",
    "\n",
    "    async def next(\n",
    "        self,\n",
    "        with_status: bool = False,\n",
    "    ) -> _T | None:\n",
    "      try:\n",
    "        item = await self._iter.__anext__()\n",
    "        status = StreamStatus.OK\n",
    "      except StopAsyncIteration:\n",
    "        item, status = None, StreamStatus.SHUTDOWN\n",
    "\n",
    "      if with_status:\n",
    "        return item, status\n",
    "      return item\n",
    "\n",
    "    async def _to_aiter(self, iterable: Iterable[_T]) -> AsyncIterator[_T]:\n",
    "      for item in iterable:\n",
    "        # Simulate asynchronous behavior.\n",
    "        await asyncio.sleep(0)\n",
    "        yield item\n",
    "\n",
    "  if len(args) == 1 and isinstance(args[0], (AsyncIterable, Iterable)):\n",
    "    return _FromIterableStream(args[0])\n",
    "\n",
    "  return _FromIterableStream(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### of Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = of(0, 1, 2)\n",
    "test_eq(await s.next(), 0)\n",
    "test_eq(await s.next(), 1)\n",
    "test_eq(await s.next(), 2)\n",
    "test_eq(await s.next(), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = of(0, 1, 2)\n",
    "test_eq(await s.next(with_status=True), (0, StreamStatus.OK))\n",
    "test_eq(await s.next(with_status=True), (1, StreamStatus.OK))\n",
    "test_eq(await s.next(with_status=True), (2, StreamStatus.OK))\n",
    "test_eq(await s.next(with_status=True), (None, StreamStatus.SHUTDOWN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = of(range(3))\n",
    "test_eq(await tolist(s), [0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def concat(*streams: Stream[_T]) -> Stream[_T]:\n",
    "  \"\"\"Concatenates the given streams.\"\"\"\n",
    "\n",
    "  class _ConcatStream(Stream[_T]):\n",
    "\n",
    "    def __init__(self):\n",
    "      self._idx = 0\n",
    "\n",
    "    async def next(\n",
    "        self,\n",
    "        with_status: bool = False,\n",
    "    ) -> _T | None:\n",
    "      while self._idx < len(streams):\n",
    "        cur_stream = streams[self._idx]\n",
    "        item, status = await cur_stream.next(with_status=True)\n",
    "        if status == StreamStatus.OK:\n",
    "          if with_status:\n",
    "            return item, StreamStatus.OK\n",
    "          return item\n",
    "        elif status == StreamStatus.SHUTDOWN:\n",
    "          self._idx += 1\n",
    "        else:\n",
    "          assert False, f\"Unexpected status: {status}\"\n",
    "\n",
    "      if with_status:\n",
    "        return None, StreamStatus.SHUTDOWN\n",
    "      return None\n",
    "\n",
    "  return _ConcatStream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### concat Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = of(0, 1)\n",
    "s1 = of(2, 3)\n",
    "s2 = of(4, 5)\n",
    "s = concat(s0, s1, s2)\n",
    "\n",
    "test_eq(await tolist(s), [0, 1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw0 = InMemStreamWriter()\n",
    "sw1 = InMemStreamWriter()\n",
    "sr = concat(sw0.readonly(), sw1.readonly())\n",
    "\n",
    "producers_access_pattern = []\n",
    "\n",
    "async def slow_producer(sw):\n",
    "  for i in range(2):\n",
    "    await asyncio.sleep(0.05)\n",
    "    producers_access_pattern.append((\"P0\", i))\n",
    "    await sw.put(i)\n",
    "  await sw.shutdown()\n",
    "\n",
    "\n",
    "async def fast_producer(sw):\n",
    "  for i in [\"a\", \"b\"]:\n",
    "    await asyncio.sleep(0.01)\n",
    "    producers_access_pattern.append((\"P1\", i))\n",
    "    await sw.put(i)\n",
    "  await sw.shutdown()\n",
    "\n",
    "\n",
    "async with asyncio.TaskGroup() as tg:\n",
    "  t = tg.create_task(tolist(sr))\n",
    "  tg.create_task(slow_producer(sw0))\n",
    "  tg.create_task(fast_producer(sw1))\n",
    "  consumed = await t\n",
    "\n",
    "test_eq(consumed, [0, 1, \"a\", \"b\"])\n",
    "test_eq(producers_access_pattern, [(\"P1\", \"a\"), (\"P1\", \"b\"), (\"P0\", 0), (\"P0\", 1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### interleave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def interleave(*streams: Stream[_T]) -> Stream[_T]:\n",
    "  w = InMemStreamWriter()\n",
    "\n",
    "  async def consume(s):\n",
    "    nonlocal w\n",
    "    async for e in s:\n",
    "      await w.put(e)\n",
    "\n",
    "  ts = [asyncio.create_task(consume(s)) for s in streams]\n",
    "\n",
    "  async def cleanup():\n",
    "    nonlocal ts\n",
    "    await asyncio.gather(*ts)\n",
    "    await w.shutdown()\n",
    "\n",
    "  asyncio.create_task(cleanup())\n",
    "\n",
    "  return w.readonly()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### interleave Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fast_producer(sw):\n",
    "  for i in (\"a\", \"b\", \"c\"):\n",
    "    await asyncio.sleep(0.01)\n",
    "    await sw.put(i)\n",
    "  await sw.shutdown()\n",
    "\n",
    "\n",
    "async def slow_producer(sw):\n",
    "  for i in (\"x\", \"y\"):\n",
    "    await asyncio.sleep(0.016)\n",
    "    await sw.put(i)\n",
    "  await sw.shutdown()\n",
    "\n",
    "\n",
    "sw0 = InMemStreamWriter()\n",
    "sw1 = InMemStreamWriter()\n",
    "sr = interleave(sw0.readonly(), sw1.readonly())\n",
    "\n",
    "async with asyncio.TaskGroup() as tg:\n",
    "  t = tg.create_task(tolist(sr))\n",
    "  tg.create_task(fast_producer(sw0))\n",
    "  tg.create_task(slow_producer(sw1))\n",
    "\n",
    "  consumed = await t\n",
    "\n",
    "test_eq(consumed, [\"a\", \"x\", \"b\", \"c\", \"y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def flatten(s: Stream[_T | Stream[_T]]) -> Stream[_T]:\n",
    "  \"\"\"Flattens one level nested stream.\"\"\"\n",
    "\n",
    "  async def consume(s):\n",
    "    async for x in s:\n",
    "      if isinstance(x, Stream):\n",
    "        async for y in x:\n",
    "          yield y\n",
    "      else:\n",
    "        yield x\n",
    "\n",
    "  return of(consume(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### flatten Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s =  flatten(of(0, of(1, 2), 3, of(4, 5)))\n",
    "test_eq(await tolist(s) , list(range(6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s =  flatten(of([0], [1]))\n",
    "test_eq(await tolist(s) , [[0], [1]]) # only flattens streams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### streamify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def streamify(func) -> Stream[_T]:\n",
    "\n",
    "  @functools.wraps(func)\n",
    "  def wrapper(*args, **kwargs) -> Stream[_T]:\n",
    "    sw = InMemStreamWriter()\n",
    "\n",
    "    async def mk_stream():\n",
    "      nonlocal sw\n",
    "      try:\n",
    "        if asyncio.iscoroutinefunction(func):\n",
    "          result = await func(*args, **kwargs)\n",
    "        else:\n",
    "          result = func(*args, **kwargs)\n",
    "        s = of(result)  # Handles also async and sync iterables.\n",
    "        async for e in s:\n",
    "          await sw.put(e)\n",
    "      finally:\n",
    "        await sw.shutdown()\n",
    "\n",
    "    # Write to the stream in the background.\n",
    "    # FIXME: Handle errors otherwise they are silently ignored.\n",
    "    asyncio.create_task(mk_stream())\n",
    "    return sw.readonly()\n",
    "\n",
    "  return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### streamify Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@streamify\n",
    "def fn(x):\n",
    "  return x\n",
    "\n",
    "s  = fn(5)\n",
    "test_eq(isinstance(s, Stream), True)\n",
    "test_eq(await tolist(s), [5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@streamify\n",
    "def fn(*, n):\n",
    "  return range(n)\n",
    "\n",
    "s  = fn(n=5)\n",
    "test_eq(isinstance(s, Stream), True)\n",
    "test_eq(await tolist(s), [0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@streamify\n",
    "def fn(*, n):\n",
    "  yield from range(n)\n",
    "\n",
    "s  = fn(n=5)\n",
    "test_eq(isinstance(s, Stream), True)\n",
    "test_eq(await tolist(s), [0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@streamify\n",
    "async def fn(x):\n",
    "  return x\n",
    "\n",
    "s = fn(0)\n",
    "test_eq(isinstance(s, Stream), True)\n",
    "test_eq(await tolist(s), [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@streamify\n",
    "async def fn(*, n):\n",
    "  for i in range(n):\n",
    "    yield i\n",
    "\n",
    "s = fn(n=5)\n",
    "test_eq(isinstance(s, Stream), True)\n",
    "test_eq(await tolist(s), [0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def map(func, *streams) -> Stream[_T]:\n",
    "  \"\"\"Maps the given function over the given streams.\"\"\"\n",
    "\n",
    "  class _MappedStream(Stream[_T]):\n",
    "\n",
    "    async def next(\n",
    "        self,\n",
    "        with_status: bool = False,\n",
    "    ) -> _T | None:\n",
    "      args = []\n",
    "      for s in streams:\n",
    "        e, status = await s.next(with_status=True)\n",
    "        if status != StreamStatus.OK:\n",
    "          return None, status\n",
    "        args.append(e)\n",
    "\n",
    "      if asyncio.iscoroutinefunction(func):\n",
    "        result = await func(*args)\n",
    "      else:\n",
    "        result = func(*args)\n",
    "\n",
    "      if with_status:\n",
    "        return result, StreamStatus.OK\n",
    "      return result\n",
    "\n",
    "  return _MappedStream()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### map Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = map(lambda x: x + 1, of(0, 1, 2))\n",
    "test_eq(await tolist(s), [1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = map(lambda x, y: x + y, of(0, 1, 2), of(3, 4, 5))\n",
    "test_eq(await tolist(s), [3, 5, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = map(lambda x, y: x + y, of(0, 1), of(3, 4, 5))\n",
    "test_eq(await tolist(s), [3, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def upper(s: str):\n",
    "  await asyncio.sleep(0.01)\n",
    "  return s.upper()\n",
    "\n",
    "s = map(upper, of(\"a\", \"b\", \"c\"))\n",
    "test_eq(await tolist(s), [\"A\", \"B\", \"C\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
