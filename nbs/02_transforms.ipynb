{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transforms\n",
    "\n",
    "> Channel transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import abc\n",
    "import asyncio\n",
    "import time\n",
    "import uuid\n",
    "import inspect\n",
    "import contextlib\n",
    "import contextvars\n",
    "import dataclasses\n",
    "from typing import Any, Callable, ParamSpec, Protocol, Generic, TypeVar, Awaitable\n",
    "import functools\n",
    "\n",
    "from fastcore.basics import patch\n",
    "\n",
    "import fastagent_hacking.streams as sx\n",
    "import fastagent_hacking.channels as cx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "_I = TypeVar('I')\n",
    "_O = TypeVar('O')\n",
    "\n",
    "\n",
    "class Transform(abc.ABC, Generic[_I, _O]):\n",
    "\n",
    "  @abc.abstractmethod\n",
    "  def __call__(self, chan: cx.Channel[_I]) -> cx.Channel[_O]:\n",
    "    \"\"\"Transforms the input channel into an output channel.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "# FIXME: Move this to a separate module.\n",
    "def _print_task_errors(task: asyncio.Task):\n",
    "  if task.exception():\n",
    "    task.print_stack()\n",
    "    print(f\"Task failed with exception: {task.exception()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ParDo Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import collections\n",
    "\n",
    "\n",
    "class ParDo(Transform[_I, _O]):\n",
    "  \"\"\"Processes each element in the input channel using a user-defined function.\"\"\"\n",
    "\n",
    "  def __init__(self, fn):  # FIXME: type hint\n",
    "    self._fn = fn\n",
    "\n",
    "    # Maintains a mapping from a packet.tag to a list of stream cancellation functions.\n",
    "    # When a cancellation packet is received, all tasks associated with the tag\n",
    "    # should be cancelled.\n",
    "    # FIXME: Terminated tasks are currently not removed from the map.\n",
    "    self._cncls_map = collections.defaultdict(list[Callable])\n",
    "\n",
    "    self._bg_tasks = set()\n",
    "\n",
    "  def __call__(self, chan: cx.Channel[_I]) -> cx.Channel[_O]:\n",
    "    main_stream = sx.InMemStreamWriter()\n",
    "    side_stream = sx.InMemStreamWriter()\n",
    "\n",
    "    async def proc(chan):\n",
    "      try:\n",
    "        async for p in chan:\n",
    "          assert isinstance(p, cx.Packet)\n",
    "          if self._is_passthrough(p):\n",
    "            await side_stream.put(p)\n",
    "            if p.packet_type == cx.PacketType.CANCELLATION_PACKET:\n",
    "              # Cancel all tasks associated with the tag.\n",
    "              cncl_tag = p.payload\n",
    "              for cncl in self._cncls_map[cncl_tag]:\n",
    "                cncl()\n",
    "              del self._cncls_map[p.payload]\n",
    "            continue\n",
    "\n",
    "          s = self._proc_packet(p)\n",
    "          await main_stream.put(s)\n",
    "      finally:\n",
    "        await main_stream.shutdown()\n",
    "        await side_stream.shutdown()\n",
    "\n",
    "    t = asyncio.create_task(proc(chan))\n",
    "    self._bg_tasks.add(t)\n",
    "    t.add_done_callback(_print_task_errors)\n",
    "    t.add_done_callback(self._bg_tasks.discard)\n",
    "\n",
    "    return cx.as_chan(\n",
    "        sx.interleave(\n",
    "            side_stream.readonly(),\n",
    "            sx.flatten(main_stream.readonly()),\n",
    "        ))\n",
    "\n",
    "  def _proc_packet(self, p: cx.Packet[_I]) -> sx.Stream[cx.Packet[_O]]:\n",
    "    assert p.packet_type == cx.PacketType.DATA\n",
    "    s, cncl = sx.streamify(self._fn, return_shutdown_fn=True)(p.payload)\n",
    "    for tag in p.tags:\n",
    "      self._cncls_map[tag].append(cncl)\n",
    "    return sx.map(\n",
    "        lambda x: cx.Packet(\n",
    "            payload=x,\n",
    "            packet_type=cx.PacketType.DATA,\n",
    "            parent_packet_id=p.packet_id,\n",
    "            tags=p.tags,\n",
    "        ),\n",
    "        s,\n",
    "    )\n",
    "\n",
    "  def _is_passthrough(self, p: cx.Packet) -> bool:\n",
    "    return p.packet_type != cx.PacketType.DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def as_transform(fn: Callable | Transform) -> Transform:\n",
    "  \"\"\"Converts a function of a single argument into a Transform object.\"\"\"\n",
    "  if isinstance(fn, Transform):\n",
    "    return fn\n",
    "\n",
    "  return ParDo(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "@patch\n",
    "def __or__(\n",
    "    self: Transform,\n",
    "    other,\n",
    ") -> Transform:\n",
    "  t1, t2 = self, as_transform(other)\n",
    "\n",
    "  class ComposedTransform(Transform):\n",
    "\n",
    "    def __call__(self, chan: cx.Channel) -> cx.Channel:\n",
    "      return t2(t1(chan))\n",
    "\n",
    "  return ComposedTransform()\n",
    "\n",
    "\n",
    "@patch\n",
    "def __ror__(\n",
    "    self: Transform,\n",
    "    other,\n",
    ") -> Transform:\n",
    "  t2, t1 = self, as_transform(other)\n",
    "\n",
    "  class ComposedTransform(Transform):\n",
    "\n",
    "    def __call__(self, chan: cx.Channel) -> cx.Channel:\n",
    "      return t2(t1(chan))\n",
    "\n",
    "  return ComposedTransform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_packet(payload) -> cx.Packet:\n",
    "  return cx.Packet(\n",
    "      payload=payload,\n",
    "      packet_type=cx.PacketType.DATA,\n",
    "      packet_id='1',\n",
    "      parent_packet_id='1',\n",
    "      created_at=1,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp_packet_payloads(p1s: Iterable[cx.Packet], p2s: Iterable[cx.Packet]):\n",
    "  p1s = list(map(lambda x: x.payload, p1s))\n",
    "  p2s = list(map(lambda x: x.payload, p2s))\n",
    "  return p1s == p2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fn(x):\n",
    "  await asyncio.sleep(0.1 * x)\n",
    "  return x + 1\n",
    "\n",
    "s = sx.of(\n",
    "    fake_packet(1),\n",
    "    fake_packet(2),\n",
    "    fake_packet(3),\n",
    ")\n",
    "sink = cx.as_chan(s)\n",
    "\n",
    "t = ParDo(fn)\n",
    "\n",
    "start = time.monotonic()\n",
    "got = await sx.tolist(t(sink))\n",
    "end = time.monotonic()\n",
    "\n",
    "test(\n",
    "  got,\n",
    "  [fake_packet(2), fake_packet(3), fake_packet(4)],\n",
    "  cmp=cmp_packet_payloads,\n",
    ")\n",
    "\n",
    "test_close(end - start, 0.3, eps=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def add1(x):\n",
    "  await asyncio.sleep(0.1 * x)\n",
    "  return x + 1\n",
    "\n",
    "async def mul2(x):\n",
    "  await asyncio.sleep(0.1 * x)\n",
    "  return x * 2\n",
    "\n",
    "s = sx.of(\n",
    "    fake_packet(1),\n",
    "    fake_packet(2),\n",
    "    fake_packet(2),\n",
    "    fake_packet(2),\n",
    "    fake_packet(2),\n",
    "    fake_packet(3),\n",
    ")\n",
    "sink = cx.as_chan(s)\n",
    "\n",
    "t = ParDo(add1) | ParDo(mul2)\n",
    "\n",
    "start = time.monotonic()\n",
    "got = await sx.tolist(t(sink))\n",
    "end = time.monotonic()\n",
    "\n",
    "test(\n",
    "  got,\n",
    "  [fake_packet(4), fake_packet(6), fake_packet(6), fake_packet(6), fake_packet(6), fake_packet(8)],\n",
    "  cmp=cmp_packet_payloads,\n",
    ")\n",
    "\n",
    "# The total time is the time of the longest task: \n",
    "# tfn(fake_packet(3)) -> @add1(3) [0.3s] -> @mul2(4) [0.4s] => 0.7s\n",
    "test_close(end - start, 0.7, eps=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def add1(x):\n",
    "  await asyncio.sleep(0.01 * x)\n",
    "  return x + 1\n",
    "\n",
    "\n",
    "s = sx.of(fake_packet(1))\n",
    "sink = cx.as_chan(s)\n",
    "\n",
    "t = ParDo(add1) | ParDo(add1) | ParDo(add1) | ParDo(add1)\n",
    "\n",
    "start = time.monotonic()\n",
    "got = await sx.tolist(t(sink))\n",
    "end = time.monotonic()\n",
    "\n",
    "test(\n",
    "  got,\n",
    "  [fake_packet(5)],\n",
    "  cmp=cmp_packet_payloads,\n",
    ")\n",
    "# 0.01 + 0.02 + 0.03 + 0.04 = 0.1\n",
    "test_close(end - start, 0.1, eps=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def add1(x):\n",
    "  await asyncio.sleep(0.01 * x)\n",
    "  return x + 1\n",
    "\n",
    "\n",
    "s = sx.of(fake_packet(1))\n",
    "sink = cx.as_chan(s)\n",
    "\n",
    "# The 1st add1 will be lifted to a transform because the 2nd add1 is a transform.s\n",
    "t = add1 | ParDo(add1)\n",
    "\n",
    "start = time.monotonic()\n",
    "got = await sx.tolist(t(sink))\n",
    "end = time.monotonic()\n",
    "\n",
    "test(\n",
    "  got,\n",
    "  [fake_packet(3)],\n",
    "  cmp=cmp_packet_payloads,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that generators can also be used in `ParDo` transforms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def mk_chunks(s: str):\n",
    "  for x in s.split():\n",
    "    yield x\n",
    "\n",
    "s = sx.of(fake_packet(\"A B C\"))\n",
    "chan = cx.as_chan(s)\n",
    "\n",
    "# The 1st add1 will be lifted to a transform because the 2nd add1 is a transform.s\n",
    "t = ParDo(mk_chunks)\n",
    "\n",
    "start = time.monotonic()\n",
    "got = await sx.tolist(t(chan))\n",
    "end = time.monotonic()\n",
    "\n",
    "test(\n",
    "  got,\n",
    "  [fake_packet(\"A\"), fake_packet(\"B\"), fake_packet(\"C\")],\n",
    "  cmp=cmp_packet_payloads,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def mk_chunks(s: str):\n",
    "  for x in s.split():\n",
    "    await asyncio.sleep(0.1)\n",
    "    yield x\n",
    "\n",
    "async def repeat(x):\n",
    "  for _ in range(2):\n",
    "    await asyncio.sleep(0.1)\n",
    "    yield x\n",
    "\n",
    "s = sx.of(fake_packet(\"A B\"))\n",
    "chan = cx.as_chan(s)\n",
    "\n",
    "# The 1st add1 will be lifted to a transform because the 2nd add1 is a transform.s\n",
    "t = ParDo(mk_chunks) | ParDo(repeat)\n",
    "\n",
    "start = time.monotonic()\n",
    "got = await sx.tolist(t(chan))\n",
    "end = time.monotonic()\n",
    "\n",
    "test(\n",
    "  got,\n",
    "  [fake_packet(\"A\"), fake_packet(\"A\"), fake_packet(\"B\"), fake_packet(\"B\")],\n",
    "  cmp=cmp_packet_payloads,\n",
    ")\n",
    "\n",
    "# Execution sketch:\n",
    "#  - mk_chunks(\"A B\") (@t=0)\n",
    "#     - yield \"A\" (@t=0.1)\n",
    "#        - repeat(\"A\") (@t=0.1)\n",
    "#           - yield \"A\" (@t=0.2)\n",
    "#           - yield \"A\" (@t=0.3)  \n",
    "#     - yield \"B\" (@t=0.2)\n",
    "#        - repeat(\"B\") (@t=0.2)\n",
    "#           - yield \"B\" (@t=0.3)\n",
    "#           - yield \"B\" (@t=0.4)\n",
    "test_close(end - start, 0.4, eps=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SeqDo Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "class SeqDo(Transform[_I, _O]):\n",
    "  \"\"\"Processes each element in the input channel using a user-defined function.\"\"\"\n",
    "\n",
    "  def __init__(self, fn):  # FIXME: type hint\n",
    "    assert inspect.isasyncgenfunction(fn) or asyncio.iscoroutinefunction(\n",
    "        fn), f\"Expected an async function, got {fn}\"\n",
    "    self._fn = fn\n",
    "\n",
    "  def __call__(self, chan: cx.Channel[_I]) -> cx.Channel[_O]:\n",
    "    writer = sx.InMemStreamWriter()\n",
    "\n",
    "    async def proc(chan):\n",
    "      try:\n",
    "        async for p in chan:\n",
    "          assert isinstance(p, cx.Packet)\n",
    "          if self._is_passthrough(p):\n",
    "            await writer.put(p)\n",
    "            continue\n",
    "          fn = sx.streamify(self._fn)\n",
    "          # FIXME: This loop blocks side packets from being processed.\n",
    "          async for e in fn(p.payload):\n",
    "            await writer.put(\n",
    "                cx.Packet(\n",
    "                    payload=e,\n",
    "                    packet_type=cx.PacketType.DATA,\n",
    "                    parent_packet_id=p.packet_id,\n",
    "                    tags=p.tags,\n",
    "                ),)\n",
    "      finally:\n",
    "        await writer.shutdown()\n",
    "\n",
    "    asyncio.create_task(proc(chan)).add_done_callback(_print_task_errors)\n",
    "\n",
    "    return cx.as_chan(writer.readonly())\n",
    "\n",
    "  def _is_passthrough(self, p: cx.Packet) -> bool:\n",
    "    return p.packet_type != cx.PacketType.DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SeqDo tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def add1(x):\n",
    "  await asyncio.sleep(0.1)\n",
    "  return x + 1\n",
    "\n",
    "s = sx.of(fake_packet(0), fake_packet(10), fake_packet(100))\n",
    "sink = cx.as_chan(s)\n",
    "\n",
    "t = SeqDo(add1) | SeqDo(add1)\n",
    "\n",
    "start = time.monotonic()\n",
    "got = await sx.tolist(t(sink))\n",
    "end = time.monotonic()\n",
    "\n",
    "test(\n",
    "  got,\n",
    "  [fake_packet(2), fake_packet(12), fake_packet(102)],\n",
    "  cmp=cmp_packet_payloads,\n",
    ")\n",
    "\n",
    "# The total time is the time of the longest task:\n",
    "# packet 1: add1(0) -> add1(1) => 2\n",
    "# packet 2:         -> add1(10) -> add1(11) => 12\n",
    "# packet 3:                     -> add1(100) -> add1(101) => 102\n",
    "# Each step takes 0.1s, so the total time is 0.4s.\n",
    "test_close(end - start, 0.4, eps=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def mk_chunks(s: str):\n",
    "  for x in s.split():\n",
    "    await asyncio.sleep(0.1)\n",
    "    yield x\n",
    "\n",
    "async def tolower(s: str):\n",
    "  await asyncio.sleep(0.15)\n",
    "  return s.lower()\n",
    "\n",
    "s = sx.of(fake_packet(\"A B\"))\n",
    "sink = cx.as_chan(s)\n",
    "\n",
    "t = SeqDo(mk_chunks) | SeqDo(tolower)\n",
    "\n",
    "start = time.monotonic()\n",
    "got = await sx.tolist(t(sink))\n",
    "end = time.monotonic()\n",
    "\n",
    "test(\n",
    "  got,\n",
    "  [fake_packet(\"a\"), fake_packet(\"b\")],\n",
    "  cmp=cmp_packet_payloads,\n",
    ")\n",
    "\n",
    "# The total time is the time of the longest task:\n",
    "# \"A B\" -> mk_chunks(\"A B\") \n",
    "#            |_ \"A\" [T=0.1] -> tolower(\"A\") -> \"a\" [T=0.25]\n",
    "#            |_ \"B\" [T=0.2] ->    WAITING   -> tolower(\"B\") -> \"b\" [T=0.4]\n",
    "test_close(end - start, 0.4, eps=0.01)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CancelPrev Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "class CancelPrev(Transform[_I, _O]):\n",
    "  \"\"\"Cancels previous packets and their derivatives when a new packet arrives.\n",
    "\n",
    "  This is useful when you want to ensure that only the latest packet is processed.\n",
    "  For example to avoid double texting in a chat application: When I user sends a new message,\n",
    "  while the previous message is still being processed, we may want to cancel the processing of\n",
    "  the previous message.\n",
    "  \"\"\"\n",
    "\n",
    "  def __call__(self, chan: cx.Channel[_I]) -> cx.Channel[_O]:\n",
    "    writer = sx.InMemStreamWriter()\n",
    "\n",
    "    async def proc(chan):\n",
    "      abort_tag = \"\"\n",
    "      try:\n",
    "        async for p in chan:\n",
    "          assert isinstance(p, cx.Packet)\n",
    "\n",
    "          # We broadcast a cancellation packet that targtets the previous\n",
    "          # packet and its derivatives.\n",
    "          if abort_tag:\n",
    "            await writer.put(cx.mk_cancellation_packet(tag=abort_tag))\n",
    "\n",
    "          # Compute a new abort tag for the next packet.\n",
    "          abort_tag = f\"latch-{str(uuid.uuid4())}\"\n",
    "          await writer.put(\n",
    "              cx.Packet(\n",
    "                  payload=p.payload,\n",
    "                  packet_type=cx.PacketType.DATA,\n",
    "                  parent_packet_id=p.packet_id,\n",
    "                  tags=(*p.tags, abort_tag),\n",
    "              ),)\n",
    "      finally:\n",
    "        await writer.shutdown()\n",
    "\n",
    "    asyncio.create_task(proc(chan)).add_done_callback(_print_task_errors)\n",
    "\n",
    "    return cx.as_chan(writer.readonly())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latch Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def add1(x):\n",
    "  await asyncio.sleep(0.1)\n",
    "  return x + 1\n",
    "\n",
    "\n",
    "t = CancelPrev() | ParDo(add1)\n",
    "\n",
    "s = sx.of(fake_packet(0), fake_packet(10))\n",
    "chan = cx.as_chan(s)\n",
    "\n",
    "got = await sx.tolist(sx.filter(\n",
    "  lambda x: x.packet_type == cx.PacketType.DATA,\n",
    "   t(chan),\n",
    "))\n",
    "\n",
    "test(\n",
    "  got,\n",
    "  [fake_packet(11)],\n",
    "  cmp=cmp_packet_payloads,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The TFN lift decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "@dataclasses.dataclass(frozen=True)\n",
    "class Event:\n",
    "  payload: Any\n",
    "  src: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "_R = TypeVar('_R')\n",
    "_P = ParamSpec('_P')\n",
    "\n",
    "\n",
    "class Streamable(Protocol[_P, _R]):\n",
    "\n",
    "  def __call__(self, *args: _P.args, **kwargs: _P.kwargs) -> _R:\n",
    "    ...\n",
    "\n",
    "  def stream(self, *args: _P.args, **kwargs: _P.kwargs) -> cx.Channel[Event]:\n",
    "    ...\n",
    "\n",
    "  def __or__(self, other) -> Transform:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "_sink_ctxvar = contextvars.ContextVar('_sink_contextvar', default=None)\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def use_sink(sink: sx.StreamWriter):\n",
    "  try:\n",
    "    tok = _sink_ctxvar.set(sink)\n",
    "    yield sink\n",
    "  finally:\n",
    "    _sink_ctxvar.reset(tok)\n",
    "\n",
    "\n",
    "def cur_sink() -> sx.StreamWriter | None:\n",
    "  return _sink_ctxvar.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "# FIXME How to improve the type hinting for decorated @tfn functions? (e.g., keep their signature).\n",
    "\n",
    "\n",
    "def tfn(fn: Callable[..., Awaitable[_R]]) -> Streamable:\n",
    "  assert asyncio.iscoroutinefunction(fn) or inspect.isasyncgenfunction(\n",
    "      fn), \"tfn can only be used with async functions or async generators\"\n",
    "\n",
    "  class _S(Streamable):\n",
    "\n",
    "    def __init__(self):\n",
    "      self._instance = None\n",
    "\n",
    "    def __get__(self, instance, owner):\n",
    "      \"\"\"Ensure correct binding for instance methods.\"\"\"\n",
    "      if instance:\n",
    "        self._instance = instance\n",
    "      return self\n",
    "\n",
    "    # TODO: Factor out the common code between __call__s.\n",
    "    if inspect.isasyncgenfunction(fn):\n",
    "\n",
    "      @functools.wraps(fn)\n",
    "      async def __call__(self, *args, **kwargs):\n",
    "        \"\"\"Handles async generators\"\"\"\n",
    "        sink = kwargs.pop(\"sink\", None)\n",
    "        if not sink:\n",
    "          sink = cur_sink()\n",
    "\n",
    "        if \"sink\" in inspect.signature(fn).parameters:\n",
    "          kwargs[\"sink\"] = sink\n",
    "\n",
    "        if self._instance:\n",
    "          # This required for decorated instance methods.\n",
    "          args = (self._instance, *args)\n",
    "\n",
    "        async for e in fn(*args, **kwargs):\n",
    "          yield e  # Async generator case\n",
    "    else:\n",
    "\n",
    "      @functools.wraps(fn)\n",
    "      async def __call__(self, *args, **kwargs):\n",
    "        \"\"\"Handles normal async functions\"\"\"\n",
    "        sink = kwargs.pop(\"sink\", None)\n",
    "        if not sink:\n",
    "          sink = cur_sink()\n",
    "\n",
    "        if \"sink\" in inspect.signature(fn).parameters:\n",
    "          kwargs[\"sink\"] = sink\n",
    "\n",
    "        if self._instance:\n",
    "          # This required for decorated instance methods.\n",
    "          args = (self._instance, *args)\n",
    "\n",
    "        return await fn(*args, **kwargs)  # Normal async function case\n",
    "\n",
    "    def stream(self, *args, return_value: bool = False, **kwargs):\n",
    "      \"\"\"Returns a streamable version of the function.\"\"\"\n",
    "      sink = sx.InMemStreamWriter()\n",
    "      with use_sink(sink):\n",
    "\n",
    "        async def target():\n",
    "          nonlocal sink\n",
    "          try:\n",
    "            result = await self(\n",
    "                *args, **kwargs,\n",
    "                sink=sink)  # FIXME Should we overwrite chan if already passed?\n",
    "            if return_value:\n",
    "              await sink.put(result)\n",
    "          finally:\n",
    "            await sink.shutdown()\n",
    "\n",
    "        # TODO: We probably need a task cleanup.\n",
    "        asyncio.create_task(target()).add_done_callback(_print_task_errors)\n",
    "        return sink.readonly()\n",
    "\n",
    "    def __or__(self, other) -> Transform:\n",
    "      t1, t2 = as_transform(self), as_transform(other)\n",
    "      return t1 | t2\n",
    "\n",
    "    def __ror__(self, other) -> Transform:\n",
    "      t2, t1 = as_transform(self), as_transform(other)\n",
    "      return t1 | t2\n",
    "\n",
    "  wrapped = _S()\n",
    "  if asyncio.iscoroutinefunction(fn):\n",
    "    inspect.markcoroutinefunction(wrapped)\n",
    "\n",
    "  return wrapped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFN Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tfn\n",
    "async def add1(x: int):\n",
    "  await asyncio.sleep(0.01)\n",
    "  return x + 1\n",
    "\n",
    "test_eq(asyncio.iscoroutinefunction(add1), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C:\n",
    "  @tfn\n",
    "  async def add1(self, x: int):\n",
    "    await asyncio.sleep(0.01)\n",
    "    return x + 1\n",
    "\n",
    "c = C()\n",
    "test_eq(asyncio.iscoroutinefunction(c.add1), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: This test is failing.\n",
    "\n",
    "# @tfn\n",
    "# async def add1(x: int):\n",
    "#   await asyncio.sleep(0.01)\n",
    "#   yield x + 1\n",
    "\n",
    "# test_eq(inspect.isasyncgenfunction(add1), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tfn\n",
    "async def add1(x: int):\n",
    "  await asyncio.sleep(0.01)\n",
    "  return x + 1\n",
    "\n",
    "# Call the function directly.\n",
    "test_eq(await add1(1), 2)\n",
    "\n",
    "# Stream the function.\n",
    "s = await sx.tolist(add1.stream(1))\n",
    "test_eq([], s)\n",
    "\n",
    "# Stream the function and include the return value.\n",
    "s = await sx.tolist(add1.stream(1, return_value=True))\n",
    "test_eq(s, [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C:\n",
    "  @tfn\n",
    "  async def add1(self, x: int):\n",
    "    await asyncio.sleep(0.01)\n",
    "    return x + 1\n",
    "\n",
    "c = C()\n",
    "test_eq(await c.add1(1), 2)\n",
    "\n",
    "s = await sx.tolist(c.add1.stream(1))\n",
    "test_eq([], s)\n",
    "\n",
    "s = await sx.tolist(c.add1.stream(1, return_value=True))\n",
    "test_eq(s, [2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tfn\n",
    "async def add1(x: int):\n",
    "\n",
    "  @tfn\n",
    "  async def _do(x, sink: sx.StreamWriter | None = None):\n",
    "    await asyncio.sleep(0.01)\n",
    "    if sink:\n",
    "      await sink.put(\"A\")\n",
    "      await sink.put(\"B\")\n",
    "    return x + 1\n",
    "\n",
    "  return await _do(x)\n",
    "\n",
    "# Call the function directly.\n",
    "test_eq(await add1(1), 2)\n",
    "\n",
    "# Stream the function.\n",
    "s = await sx.tolist(add1.stream(1))\n",
    "test_eq(s, [\"A\", \"B\"])\n",
    "\n",
    "# Stream the function and include the return value.\n",
    "s = await sx.tolist(add1.stream(1, return_value=True))\n",
    "test_eq(s, [\"A\", \"B\", 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class C:\n",
    "\n",
    "  @tfn\n",
    "  async def add1(self, x: int):\n",
    "\n",
    "    @tfn\n",
    "    async def _do(x, sink: sx.StreamWriter | None = None):\n",
    "      await asyncio.sleep(0.01)\n",
    "      if sink:\n",
    "        await sink.put(\"A\")\n",
    "        await sink.put(\"B\")\n",
    "      return x + 1\n",
    "\n",
    "    return await _do(x)\n",
    "\n",
    "c = C()\n",
    "\n",
    "# Call the method directly.\n",
    "test_eq(await c.add1(1), 2)\n",
    "\n",
    "# Stream the method.\n",
    "s = await sx.tolist(add1.stream(1))\n",
    "test_eq(s, [\"A\", \"B\"])\n",
    "\n",
    "# Stream the method and include the return value.\n",
    "s = await sx.tolist(add1.stream(1, return_value=True))\n",
    "test_eq(s, [\"A\", \"B\", 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tfn\n",
    "async def mk_chunks(s: str):\n",
    "  for x in s.split():\n",
    "    await asyncio.sleep(0.1)\n",
    "    yield x\n",
    "\n",
    "@tfn\n",
    "async def repeat(x):\n",
    "  for _ in range(2):\n",
    "    await asyncio.sleep(0.1)\n",
    "    yield x\n",
    "\n",
    "s = sx.of(fake_packet(\"A B\"))\n",
    "chan = cx.as_chan(s)\n",
    "\n",
    "t = mk_chunks | repeat\n",
    "\n",
    "start = time.monotonic()\n",
    "got = await sx.tolist(t(chan))\n",
    "end = time.monotonic()\n",
    "\n",
    "test(\n",
    "  got,\n",
    "  [fake_packet(\"A\"), fake_packet(\"A\"), fake_packet(\"B\"), fake_packet(\"B\")],\n",
    "  cmp=cmp_packet_payloads,\n",
    ")\n",
    "\n",
    "# Execution sketch:\n",
    "#  - mk_chunks(\"A B\") (@t=0)\n",
    "#     - yield \"A\" (@t=0.1)\n",
    "#        - repeat(\"A\") (@t=0.1)\n",
    "#           - yield \"A\" (@t=0.2)\n",
    "#           - yield \"A\" (@t=0.3)  \n",
    "#     - yield \"B\" (@t=0.2)\n",
    "#        - repeat(\"B\") (@t=0.2)\n",
    "#           - yield \"B\" (@t=0.3)\n",
    "#           - yield \"B\" (@t=0.4)\n",
    "test_close(end - start, 0.4, eps=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: P0 Agent runner\n",
    "# TODO: P1 Add a playground (text msgs)\n",
    "# TODO: P1 Add wrapper to OpenAI realtime API.\n",
    "# TODO: P1 Add a simple tracer.\n",
    "# TODO: P2 Make .stream liftable to ParDo transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
