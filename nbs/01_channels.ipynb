{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Channels\n",
    "\n",
    "> Channel data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import abc\n",
    "import asyncio\n",
    "import enum\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Generic, TypeVar, Sequence\n",
    "\n",
    "import fastagent_hacking.streams as sx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "_T = TypeVar('T')\n",
    "\n",
    "\n",
    "class PacketType(enum.StrEnum):\n",
    "  DATA = enum.auto()\n",
    "  LOG_PACKET = enum.auto()\n",
    "  EVENT_PACKET = enum.auto()\n",
    "  CANCELLATION_PACKET = enum.auto()\n",
    "\n",
    "\n",
    "def _current_time_ms() -> float:\n",
    "  return time.time() * 1000\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class Packet(Generic[_T]):\n",
    "  \"\"\"Represents a unit of data inside a Channel\n",
    "  \n",
    "  Attributes:\n",
    "    payload: The data that the packet carries.\n",
    "    packet_type: The type of the packet.\n",
    "    packet_id: ID for the packet. Default is a random UUID.\n",
    "    parent_packet_id: ID of the packet that this packet is derived from if any.\n",
    "      Default is None.\n",
    "    created_at: The time the packet was created in milliseconds.\n",
    "    priority: A number that indicates the priority of the packet relative to other \n",
    "      _buffered_ packets in the same channel. The higher the number, the higher the priority.\n",
    "    tags: A sequence of indenpendent labels that can be used to filter packets with.\n",
    "      Derived packets do not necessarily inherit the tags of their parent packets.\n",
    "      It's up to the packet creator to decide whether to copy the tags or not.\n",
    "  \"\"\"\n",
    "  payload: _T  # FIXME: This type should be serializeable.\n",
    "  packet_type: PacketType\n",
    "  packet_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n",
    "  parent_packet_id: str | None = None\n",
    "  created_at: float = field(default_factory=_current_time_ms)\n",
    "  priority: int = 0\n",
    "  tags: Sequence[str] = ()\n",
    "\n",
    "  def __post_init__(self):\n",
    "    if not isinstance(self.tags, tuple):\n",
    "      # Ensure immutability.\n",
    "      object.__setattr__(self, 'tags', tuple(self.tags))\n",
    "\n",
    "  def to_json(self):\n",
    "    return json.dumps(\n",
    "        self,\n",
    "        default=lambda o: o.__dict__,\n",
    "        sort_keys=True,\n",
    "        indent=2,\n",
    "    )\n",
    "\n",
    "  @classmethod\n",
    "  def from_json(cls, json_str):\n",
    "    return cls(**json.loads(json_str))\n",
    "\n",
    "  def __lt__(self, other: \"Packet[Any]\") -> bool:\n",
    "    \"\"\"Compare packets for priority queue ordering.\n",
    "      Higher priority comes first, then older packets.\"\"\"\n",
    "    if self.priority != other.priority:\n",
    "      return self.priority > other.priority\n",
    "    return self.created_at < other.created_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Packet(\n",
    "    payload=1,\n",
    "    packet_type=PacketType.DATA,\n",
    "    packet_id='1',\n",
    "    parent_packet_id='1',\n",
    ")\n",
    "\n",
    "test_eq(p, Packet.from_json(p.to_json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_packet(payload, *, priority=0, tags=()) -> Packet:\n",
    "  return Packet(\n",
    "      payload=payload,\n",
    "      packet_type=PacketType.DATA,\n",
    "      priority=priority,\n",
    "      tags=tags,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same priority, older packet comes first.\n",
    "p0 = fake_packet(0)\n",
    "p1 = fake_packet(1)\n",
    "\n",
    "test_eq(p0 < p1, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higher priority comes first.\n",
    "p0 = fake_packet(0, priority=0)\n",
    "p1 = fake_packet(1, priority=1)\n",
    "\n",
    "test_eq(p1 < p0, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = fake_packet(0, priority=1)\n",
    "p1 = fake_packet(1, priority=0)\n",
    "p2 = fake_packet(2, priority=0)\n",
    "p3 = fake_packet(3, priority=3)\n",
    "\n",
    "test_eq(sorted([p0, p1, p2, p3]), [p3, p0, p1, p2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STD Packets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cancellation Packets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "def mk_cancellation_packet(*, tag: str) -> Packet:\n",
    "  \"\"\"Creates a packet that can be used to cancel packets with the same tag.\n",
    "\n",
    "  Cancellation packets are propagated through the network through the side channels.\n",
    "  Channels that receive a cancellation packet should cancel all packets with the same `tag`.\n",
    "  \"\"\"\n",
    "  return Packet(\n",
    "      payload=tag,\n",
    "      packet_type=PacketType.CANCELLATION_PACKET,\n",
    "      packet_id=str(uuid.uuid4()),\n",
    "      priority=128,\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "class Channel(sx.Stream[Packet[Any]], Generic[_T]):\n",
    "  pass\n",
    "\n",
    "\n",
    "def as_chan(s: sx.Stream[Packet[Any]]) -> Channel[_T]:\n",
    "  \"\"\"Coerce a stream of packets to a channel. Do not use `s` after this function.\"\"\"\n",
    "\n",
    "  class _ChanStream(Channel[_T]):\n",
    "\n",
    "    def __init__(self):\n",
    "      super().__init__()\n",
    "      self._pq = asyncio.PriorityQueue()\n",
    "      self._bad_tags = set()  # FIXME: This can grow indefinitely.\n",
    "\n",
    "      asyncio.create_task(\n",
    "          self._pull_from_stream(s)).add_done_callback(_print_task_errors)\n",
    "\n",
    "    async def next(self, with_status: bool = False) -> Packet[Any]:\n",
    "      packet, status = None, None\n",
    "      try:\n",
    "        packet = await self._pq.get()\n",
    "        status = sx.StreamStatus.OK\n",
    "      except asyncio.QueueShutDown:\n",
    "        packet, status = None, sx.StreamStatus.SHUTDOWN\n",
    "\n",
    "      if (p := packet):\n",
    "        if p.packet_type == PacketType.CANCELLATION_PACKET:\n",
    "          self._bad_tags.add(p.payload)\n",
    "        elif self._bad_tags & set(p.tags):\n",
    "          # Skip this packet and try the next one.\n",
    "          return await self.next(with_status=with_status)\n",
    "\n",
    "      if with_status:\n",
    "        return packet, status\n",
    "      return packet\n",
    "\n",
    "    async def _pull_from_stream(self, s: sx.Stream[Packet[Any]]):\n",
    "      async for p in s:\n",
    "        await self._pq.put(p)\n",
    "      self._pq.shutdown()\n",
    "\n",
    "  return _ChanStream()\n",
    "\n",
    "\n",
    "# FIXME: This is a hack to print errors in async tasks.\n",
    "def _print_task_errors(task: asyncio.Task):\n",
    "  if task.exception():\n",
    "    task.print_stack()\n",
    "    print(f\"Task failed with exception: {task.exception()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "class ChannelWriter(sx.StreamWriter[Packet[Any]], Generic[_T]):\n",
    "  elm_type: type[_T]  # Main packet payload type of the channel\n",
    "\n",
    "  @abc.abstractmethod\n",
    "  def readonly(self) -> Channel[_T]:\n",
    "    \"\"\"Return a readonly version of the channel\"\"\"\n",
    "\n",
    "\n",
    "def as_chan_writer(s: sx.StreamWriter[Packet[Any]]) -> ChannelWriter[_T]:\n",
    "  \"\"\"Coerce a stream writer of packets to a channel writer. Do not use `s` after this function.\"\"\"\n",
    "\n",
    "  class _ChanWriter(ChannelWriter[_T]):\n",
    "\n",
    "    async def put(self, *args, **kwargs):\n",
    "      assert all(isinstance(a, Packet) for a in args)\n",
    "      await s.put(*args, **kwargs)\n",
    "\n",
    "    async def shutdown(self, *args, **kwargs):\n",
    "      await s.shutdown(*args, **kwargs)\n",
    "\n",
    "    def readonly(self, *args, **kwargs) -> Channel[_T]:\n",
    "      return as_chan(s.readonly(*args, **kwargs))\n",
    "\n",
    "  return _ChanWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = fake_packet(0)\n",
    "p1 = fake_packet(\"a\")\n",
    "\n",
    "chan = as_chan(sx.of(p0, p1))\n",
    "\n",
    "test_eq(isinstance(chan, Channel), True)\n",
    "\n",
    "ps = []\n",
    "async for p in chan:\n",
    "  ps.append(p)\n",
    "test_eq(ps, [p0, p1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_writer = as_chan_writer(sx.InMemStreamWriter())\n",
    "\n",
    "test_eq(isinstance(chan_writer, ChannelWriter), True)\n",
    "\n",
    "p0 = fake_packet(\"a\")\n",
    "p1 =  fake_packet(\"b\")\n",
    "\n",
    "await chan_writer.put(p0, p1)\n",
    "await chan_writer.shutdown()\n",
    "\n",
    "ps = []\n",
    "chan = chan_writer.readonly()\n",
    "async for p in chan:\n",
    "  ps.append(p)\n",
    "test_eq(ps, [p0, p1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = fake_packet(0)\n",
    "p1 = fake_packet(1)\n",
    "p2 = fake_packet(2)\n",
    "p3 = fake_packet(3)\n",
    "\n",
    "c0 = as_chan(sx.of(p0, p1))\n",
    "c1 = as_chan(sx.of(p2, p3))\n",
    "\n",
    "ps = []\n",
    "async for payload in sx.concat(c0, c1):\n",
    "  ps.append(payload)\n",
    "\n",
    "test_eq(ps, [p0, p1, p2, p3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = mk_cancellation_packet(tag=\"xyz\")\n",
    "p1 = fake_packet(1, tags=(\"xyz\",))\n",
    "p2 = fake_packet(2, tags=(\"xyz\",))\n",
    "p3 = fake_packet(3, tags=(\"abc\",))\n",
    "p4 = fake_packet(4)\n",
    "\n",
    "chan = as_chan(sx.of(p0, p1, p2, p3, p4))\n",
    "\n",
    "ps = []\n",
    "async for p in chan:\n",
    "  ps.append(p)\n",
    "\n",
    "test_eq(ps, [p0, p3, p4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = fake_packet(0, tags=(\"xyz\",))\n",
    "p1 = mk_cancellation_packet(tag=\"xyz\") \n",
    "# Cancellation packets have higher priority than normal packets.\n",
    "\n",
    "chan = as_chan(sx.of(p0, p1))\n",
    "\n",
    "await asyncio.sleep(0.01) # Wait for the cancellation packet to be propagated.\n",
    "\n",
    "ps = []\n",
    "async for p in chan:\n",
    "  ps.append(p)\n",
    "\n",
    "test_eq(ps, [p1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
